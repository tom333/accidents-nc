# Industrialisation avec Dagster sur Kubernetes local

Ce document dÃ©crit les Ã©tapes pour industrialiser le pipeline d'accidents avec **Dagster**
sur un cluster **Kubernetes local**, en s'appuyant sur **DuckLake** pour le stockage
des donnÃ©es (moteur DuckDB managÃ©) et les composants suivants :

- Une instance Dagster (Dagster webserver + daemon) est dÃ©jÃ  dÃ©ployÃ©e sur le cluster.
- La configuration utilise `dagster-user-deployments`.
- Une base Postgres accessible via le service `postgresql` dans le namespace `datalab`,
  utilisÃ©e comme mÃ©tastore DuckLake.
- Un service compatible S3 (RustFS) accessible via le service `rustfs-svc` dans le
  namespace `ia-lab`, utilisÃ© comme stockage objet pour DuckLake.
- Un volume (PersistentVolume / hostPath) est montÃ© dans le pod user-deployment et expose
  le code local du projet `accidents`.

## Architecture MÃ©daillons (Bronze/Silver/Gold)

Le pipeline est organisÃ© selon l'architecture **mÃ©daillons** standard des lakehouses :

### ğŸ¥‰ Bronze Layer (DonnÃ©es brutes)
- **SchÃ©ma** : `bronze`
- **Tables** : 
  - `bronze.caracteristiques` : CSV bruts data.gouv.fr 2019-2024
  - `bronze.usagers` : CSV usagers data.gouv.fr
  - `bronze.accidents_nc` : accidents New Caledonia (dep=988) jointure carac+usagers
- **Asset Dagster** : `bronze_accidents_nc`
- **Transformation** : ingestion brute avec filtrage dÃ©partement, nettoyage coordonnÃ©es
- **Idempotence** : `CREATE OR REPLACE TABLE`

### ğŸ¥ˆ Silver Layer (DonnÃ©es enrichies)
- **SchÃ©ma** : `silver`
- **Tables** :
  - `silver.full_dataset` : features enrichies (positifs + nÃ©gatifs synthÃ©tiques)
- **Asset Dagster** : `silver_features`
- **Transformations** :
  - Parsing datetime (jour/mois/an hrmn â†’ features temporelles)
  - Enrichissement routier OSMnx (buffer 200m, comptage intersections)
  - GÃ©nÃ©ration nÃ©gatifs synthÃ©tiques (ratio 22k, sampling des marginales)
  - Features d'interaction (hourÃ—weekend, monthÃ—dayofweek)
- **QualitÃ©** : dÃ©dupliquÃ©, valeurs nulles gÃ©rÃ©es, gÃ©olocalisation validÃ©e

### ğŸ¥‡ Gold Layer (Datasets ML & ModÃ¨les)
- **SchÃ©ma** : `gold`
- **Tables** :
  - `gold.train` : dataset train (80%)
  - `gold.test` : dataset test (20%)
  - `gold.feature_metadata` : ordre et noms des features
- **Assets Dagster** : `gold_datasets`, `gold_models`
- **Artefacts** :
  - `atm_encoder.pkl` : LabelEncoder pour mÃ©tÃ©o
  - `features.pkl` : liste des features pour prÃ©diction
  - `accident_model.pkl` : meilleur modÃ¨le (RandomForest, LGBM, XGB, CatBoost, TabNet ou MLP)
- **MLflow** : tracking des runs, mÃ©triques AUC-ROC, hyperparamÃ¨tres
- **SÃ©lection** : RandomizedSearchCV 5-fold, optimisation AUC-ROC

## 1. Structurer le code pour Dagster âœ…

1. CrÃ©er un package Dagster dÃ©diÃ© (dans ce repo) : âœ… (fait : dossier `dagster_accidents/` + fichiers de base)
   - Dossier `dagster_accidents/` (ou `accidents_dagster/`) Ã  la racine.
   - Fichiers minimum :
     - `dagster_accidents/__init__.py`
     - `dagster_accidents/jobs.py` : dÃ©finition des jobs/pipelines.
   - `dagster_accidents/assets.py` (optionnel mais recommandÃ©) : assets data (tables gÃ©rÃ©es par DuckLake / DuckDB).
     - `dagster_accidents/repository.py` : objet `Definitions` / `repository` Dagster.

2. Le code mÃ©tier reste dans `pipeline/` comme **source de vÃ©ritÃ©** (âœ… migration DuckLake dans `pipeline.config.ensure_connection`) :
   - `pipeline.stage_ingest.ingest_all` â†’ Ã©crit dans `bronze`
   - `pipeline.stage_features.build_feature_store` â†’ Ã©crit dans `silver`
   - `pipeline.stage_datasets.build_datasets` â†’ Ã©crit dans `gold`
   - `pipeline.stage_modeling.run_training` â†’ lit `gold`, Ã©crit artefacts + MLflow

3. Les ops/assets Dagster ne font que **appeler ces fonctions** en les dÃ©corant :
   - Exemple : `@op` ou `@asset` qui appelle `ingest_all()` et renvoie des mÃ©triques (dict).

4. Ajouter Dagster dans les dÃ©pendances : âœ… (fait dans `pyproject.toml`)
   - Dans `pyproject.toml` : `dagster`, `dagster-webserver`, `dagster-k8s` (si besoin).

## 2. ModÃ©liser le pipeline dans Dagster

Deux options principales :

### 2.1. ModÃ©lisation en jobs (simple)

1. CrÃ©er un fichier `dagster_accidents/jobs.py` avec :
   - Un `@job` principal (ex. `accidents_full_job`) qui enchaÃ®ne 4 `@op` :
     - `ingest_raw_op` â†’ appelle `ingest_all`.
     - `build_features_op` â†’ appelle `build_feature_store`.
     - `prepare_datasets_op` â†’ appelle `build_datasets`.
     - `train_models_op` â†’ appelle `run_training`.

2. Chaque `@op` :
   - Loggue des infos importantes (nb de lignes, AUC, etc.).
   - Renvoie un petit rÃ©sumÃ© (dict) pour inspection Ã©ventuelle.

3. Avantage :
   - TrÃ¨s proche de l'orchestrateur Python existant.
   - Facile Ã  dÃ©clencher via la Dagster UI ou cron Dagster.

### 2.2. ModÃ©lisation en assets (recommandÃ©e pour la data) âœ…

1. CrÃ©er un fichier `dagster_accidents/assets.py` avec des `@asset` reprÃ©sentant les mÃ©daillons DuckLake : âœ…
   - `bronze_accidents_nc` (key_prefix=["bronze"], group_name="bronze") â†’ Ã©crit `bronze.accidents_nc` via `ingest_all`.
   - `silver_features` (key_prefix=["silver"], group_name="silver") â†’ Ã©crit `silver.full_dataset` via `build_feature_store`.
   - `gold_datasets` (key_prefix=["gold"], group_name="gold") â†’ Ã©crit `gold.train` / `gold.test` via `build_datasets`.
   - `gold_models` (key_prefix=["gold"], group_name="gold") â†’ Ã©crit artefacts ML + MLflow via `run_training`.

2. DÃ©crire les dÃ©pendances via `deps` ou en utilisant les arguments des assets : âœ…
   - `silver_features` dÃ©pend de `bronze_accidents_nc`.
   - `gold_datasets` dÃ©pend de `silver_features`.
   - `gold_models` dÃ©pend de `gold_datasets`.

3. Avantages :
   - Vue `Asset Graph` trÃ¨s claire dans la Dagster UI avec groupes bronze/silver/gold.
   - Rebuild partiel : possibilitÃ© de ne relancer qu'un asset obsolÃ¨te.
   - TraÃ§abilitÃ© du lineage des donnÃ©es (bronze â†’ silver â†’ gold).

## 3. DÃ©finir le repository / Definitions âœ…

1. CrÃ©er `dagster_accidents/repository.py` avec : âœ… (fait : objet `defs` de type `Definitions`)
   - Soit un `Definitions` (Dagster >=1.5) :
     - `Definitions(assets=[...], jobs=[...], schedules=[...], sensors=[...])`.
   - Soit un `@repository` (ancienne API).

2. Y enregistrer : âœ… (fait : enregistrement des 4 assets bronze/silver/gold, sans jobs ni schedules pour l'instant)
   - Les jobs (`accidents_full_job`).
   - Ou/et les assets (`bronze_accidents_nc`, `silver_features`, `gold_datasets`, `gold_models`).
   - Les Ã©ventuels schedules (ex. job quotidien) pour remplacer le CronJob k8s ou le complÃ©ter.

3. VÃ©rifier localement :
   - `uv run dagster dev -m dagster_accidents.repository` (ou Ã©quivalent) pour tester la dÃ©finition.

## 4. PrÃ©parer le dÃ©ploiement Dagster sur k8s (user-deployments) âœ…

**Statut** : Fichiers de dÃ©ploiement crÃ©Ã©s dans `k8s/dagster/`

### 4.1. Image Docker âœ…

CrÃ©Ã© [Dockerfile.dagster](Dockerfile.dagster) avec :
- Base Python 3.13-slim
- DÃ©pendances systÃ¨me pour geospatial (GDAL, GEOS, PROJ)
- Installation via `uv` des packages ML/geo
- Copies des dossiers `pipeline/` et `dagster_accidents/`
- `PYTHONPATH=/opt/dagster/app`
- Exposition du port 4000 pour gRPC

### 4.2. Manifests Kubernetes âœ…

CrÃ©Ã©s dans [k8s/dagster/](k8s/dagster/) :

1. **[configmap-dagster-ducklake.yaml](k8s/dagster/configmap-dagster-ducklake.yaml)** :
   - ConfigMap avec variables DuckLake (DATABASE_URL, DATA_PATH, endpoints)
   - Secret pour credentials (AWS S3, Postgres password)

2. **[deployment-dagster-user.yaml](k8s/dagster/deployment-dagster-user.yaml)** :
   - Deployment du user-code avec commande `dagster api grpc`
   - Injection des variables d'environnement depuis ConfigMap/Secret
   - Resources : 2Gi RAM request, 4Gi limit
   - Volume mount pour stockage modÃ¨les (PVC)
   - Service ClusterIP sur port 4000

3. **[pvc-dagster-models.yaml](k8s/dagster/pvc-dagster-models.yaml)** :
   - PersistentVolumeClaim 5Gi pour artefacts ML

4. **[workspace.yaml](k8s/dagster/workspace.yaml)** :
   - Configuration workspace Dagster pointant vers `dagster-user-code-accidents:4000`
   - Location name : `accidents_pipeline`

### 4.3. Script de dÃ©ploiement automatisÃ© âœ…

CrÃ©Ã© [k8s/dagster/deploy-dagster-user.sh](k8s/dagster/deploy-dagster-user.sh) qui :
1. Build l'image Docker `accidents-dagster:latest`
2. Import dans microk8s (ou push vers registry)
3. Applique les manifests k8s (PVC, ConfigMap, Deployment)
4. Attend que le pod soit ready
5. Affiche les logs et commandes utiles

Usage : `./k8s/dagster/deploy-dagster-user.sh`

### 4.4. Documentation dÃ©taillÃ©e âœ…

Guide complet dans [k8s/dagster/DEPLOY_DAGSTER.md](k8s/dagster/DEPLOY_DAGSTER.md) :
- Architecture dÃ©ployÃ©e (diagramme)
- Configuration des credentials
- Ã‰tapes de dÃ©ploiement
- Configuration du workspace dans webserver Dagster
- Commandes de vÃ©rification et debugging
- Troubleshooting des problÃ¨mes courants

## 5. IntÃ©gration avec Kubernetes local

**RÃ©fÃ©rence** : voir [k8s/dagster/DEPLOY_DAGSTER.md](k8s/dagster/DEPLOY_DAGSTER.md) pour la procÃ©dure complÃ¨te.

### Ã‰tapes de dÃ©ploiement :

1. **Ã‰diter les credentials** dans `k8s/dagster/configmap-dagster-ducklake.yaml`

2. **Lancer le dÃ©ploiement** :
   ```bash
   ./k8s/dagster/deploy-dagster-user.sh
   ```

3. **Configurer le workspace Dagster** :
   - IntÃ©grer `k8s/dagster/workspace.yaml` dans la ConfigMap du webserver
   - Ou ajouter dans Helm values :
     ```yaml
     dagsterWebserver:
       workspace:
         servers:
           - host: dagster-user-code-accidents
             port: 4000
             location_name: accidents_pipeline
     ```

4. **RedÃ©marrer le webserver** :
   ```bash
   kubectl rollout restart deployment dagster-webserver
   ```

5. **VÃ©rification dans l'UI Dagster** :
   - Workspace "accidents_pipeline" visible
   - 4 assets bronze/silver/gold avec groupes
   - Graphe de dÃ©pendances correct

6. **Test de matÃ©rialisation** :
   - SÃ©lectionner `gold_models` dans l'UI
   - Cliquer "Materialize"
   - Dagster exÃ©cute automatiquement : bronze â†’ silver â†’ gold

### Commandes de vÃ©rification :

```bash
# Status du pod
kubectl get pods -l app=dagster-user-code,component=accidents

# Logs en temps rÃ©el
kubectl logs -f -l app=dagster-user-code,component=accidents

# Tester connectivitÃ© DuckLake
kubectl exec deployment/dagster-user-deployment-accidents -- \
  python -c "from pipeline.config import ensure_connection; conn = ensure_connection(); print('OK')"
```

## 6. Programmation et supervision

1. Schedules Dagster :
   - CrÃ©er un `ScheduleDefinition` (ou entry `schedules=[...]` dans `Definitions`) pour :
     - ExÃ©cuter `accidents_full_job` chaque nuit / heure.
   - Activer le schedule dans l'UI.

2. Remplacer ou complÃ©ter les CronJobs k8s :
   - Option A : laisser Dagster gÃ©rer la planification (recommandÃ© pour la cohÃ©rence des runs).
   - Option B : garder un CronJob k8s qui appelle l'API Dagster ou un job Dagster spÃ©cifique.

3. Monitoring :
   - Utiliser l'UI Dagster pour suivre les runs, relancer en cas d'Ã©chec.
   - Conserver MLflow pour le suivi expÃ©rimental des modÃ¨les (complÃ©mentaire Ã  Dagster).

## 7. RÃ´le des notebooks marimo aprÃ¨s migration

1. Les notebooks marimo restent des outils d'exploration et de visualisation :
   - Inspection des tables DuckLake (via un client DuckDB connectÃ© Ã  DuckLake) produites par Dagster.
   - Cartes Folium, analyses de features, SHAP, etc.

2. Ils ne sont plus responsables de l'orchestration :
   - Toute l'exÃ©cution planifiÃ©e se fait via Dagster.
   - Les notebooks peuvent Ã©ventuellement appeler des runs Dagster via l'API HTTP si besoin,
     mais ce n'est pas obligatoire.

3. Bien documenter dans README / INDUSTRIALISATION :
   - "Pipeline de production" = Dagster + k8s.
   - "Exploration / analyses ad hoc" = notebooks marimo.

## 8. Ã‰tapes pratiques de mise en Å“uvre (rÃ©sumÃ©)

### Phase 1 : DÃ©veloppement local âœ…

1. âœ… CrÃ©er le package `dagster_accidents/` et y dÃ©finir assets/jobs + repository
2. âœ… Ajouter Dagster aux dÃ©pendances du projet et tester localement (`dagster dev`)
3. âœ… ImplÃ©menter l'architecture mÃ©daillons (bronze/silver/gold)
4. âœ… Configurer `.env` avec variables DuckLake pour dev local

**Test local** : `uv run dagster dev -m dagster_accidents.repository`

### Phase 2 : PrÃ©paration k8s âœ…

3. âœ… CrÃ©er `Dockerfile.dagster` pour l'image user-deployment
4. âœ… CrÃ©er les manifests k8s dans `k8s/dagster/`
   - ConfigMap/Secret DuckLake
   - Deployment + Service
   - PVC pour modÃ¨les
   - workspace.yaml
5. âœ… CrÃ©er script de dÃ©ploiement automatisÃ©
6. âœ… Documenter dans `k8s/dagster/DEPLOY_DAGSTER.md`

### Phase 3 : DÃ©ploiement et tests (Ã  faire)

7. â³ Ã‰diter credentials dans `k8s/dagster/configmap-dagster-ducklake.yaml`
8. â³ Lancer `./k8s/dagster/deploy-dagster-user.sh`
9. â³ Configurer workspace dans webserver Dagster
10. â³ Tester un run complet via l'UI sur le k8s local
11. â³ Ajouter schedules Dagster pour l'exÃ©cution rÃ©currente
12. â³ Mettre Ã  jour la documentation (README, STREAMLIT_APP, etc.) pour reflÃ©ter l'architecture Dagster

### Organisation des fichiers k8s

Les manifests sont sÃ©parÃ©s par composant dans `k8s/` :

```
k8s/
â”œâ”€â”€ README.md                    # Index et ordre de dÃ©ploiement
â”œâ”€â”€ dagster/                     # Orchestration ML
â”‚   â”œâ”€â”€ DEPLOY_DAGSTER.md       # Guide complet
â”‚   â”œâ”€â”€ configmap-dagster-ducklake.yaml
â”‚   â”œâ”€â”€ deployment-dagster-user.yaml
â”‚   â”œâ”€â”€ pvc-dagster-models.yaml
â”‚   â”œâ”€â”€ workspace.yaml
â”‚   â””â”€â”€ deploy-dagster-user.sh
â”œâ”€â”€ streamlit/                   # Application web
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â””â”€â”€ deploy.sh
â””â”€â”€ (fichiers communs)
    â”œâ”€â”€ namespace.yaml
    â”œâ”€â”€ cronjob-training.yaml
    â””â”€â”€ setup-microk8s.sh
```
